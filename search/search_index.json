{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Toolbox Catalog","text":"<p>Welcome to AI toolbox catalog. Here it is possible to find a collection of AI tools arrange by</p> <ul> <li>Application</li> <li>AI domain</li> <li>AI tool kind</li> </ul> <p>The catalog relies on a common AI toolbox specification and a project template defined within the scope of the AIxPA project.</p>"},{"location":"PROJECT/","title":"AI Tool Project Structure","text":"<p>To facilitate the documentation and reuse of the AI tools, it is expected that every tool is provided as  a Git project that follows the common structure with thew following template:</p> <ul> <li>README.md - main documentation entry. Should have subsections briefly describing the tool, such as</li> <li>AIPC tags (kind, ai domain, application domain)</li> <li>description</li> <li>usage</li> <li>how to scenarios </li> <li>aipc.yaml - product specification</li> <li>data/ - folder with product artifacts (datasets, artifacts)</li> <li>models/ - folder with model artifacts</li> <li>src/ - folder with the source code of the operations</li> <li>docs/ - folder with the documentation. May include</li> <li>howto/ - list of markdown files with HowTo scenarios</li> <li>Other markdown documentation (e.g., usages, \u2026)</li> </ul>"},{"location":"SPEC/","title":"AI Tool Specification","text":"<p>This is a spec and structure model for AI toolbox contents. Each element is documented with structured model specification, tool repository, and documentation template.</p> <p>Types of tools:</p> <ul> <li>Library</li> <li>Supporting component</li> <li>AI product template</li> <li>AI product</li> </ul>"},{"location":"SPEC/#1-ai-tool-specification","title":"1. AI Tool Specification","text":"<p>Common metadata for tools and its entities:</p> <ul> <li>id - fully qualified name, unique for the element. Necessary for the references.</li> <li>name - name of the solution</li> <li>description - detailed description of the solution (markdown)</li> <li>version - version of the solution</li> <li>tags - label the solution so that to be easily filtered and accessible</li> <li>kind - entity-specific category</li> </ul>"},{"location":"SPEC/#11-ai-tool-specification","title":"1.1. AI-tool Specification","text":"<p>In general, AI tool as a composite software project containing one or more entities of different types.</p> <p>Kinds:</p> <ul> <li>library</li> <li>product</li> <li>component</li> <li>template</li> <li>tool</li> </ul> <p>Besides common metadata elements, the following spec elements are required</p> <ul> <li>license</li> <li>name</li> <li>ref (optional, relative or absolute URL)</li> <li>problems - list of problem tags describing what the tool addresses</li> <li>ai - AI domain (e.g., text, video, audio, \u2026)</li> <li>domain - reference to the domain type (e.g., mobility, security, civil protection, \u2026)</li> <li>usage - documentation (markdown) of the scenarios describing how the tool can be used in practice</li> <li>howto - list of HowTo scenarios describing the operations with the tool. Each howto is defined with</li> <li>title - name of the howto</li> <li>description - short description of the howto</li> <li>ref - full documentation of the procedure (markdown)</li> </ul> <p>Each AI tool may contain also the following entities</p> <ul> <li>datasets - list of data entity specs that the AI tool relies on</li> <li>models - ML model specs the tool defines or relies on</li> <li>operations - list of operations over the tool entities. This may include the exploration notebooks, deployment procedures, data processing jobs, model training, or the whole pipelines.</li> <li>deployments - list of deployable entities of the tool: AI services, data services, Web apps. </li> </ul>"},{"location":"SPEC/#12-dataset-specification","title":"1.2. Dataset Specification","text":"<p>Kinds (depend on data organization)</p> <ul> <li>table</li> <li>artifact</li> <li>...</li> </ul> <p>Besides common metadata elements, the following spec elements are allowed (optional)</p> <ul> <li>schema - definition of the dataset specification, if applies</li> <li>type - format / organization of the schema (JSON Schema, Table Schema, AVRO, \u2026)</li> <li>ref - URL of the spec file (relative or absolute)</li> <li>sample - sample data</li> <li>value - dataset instance as URL (relative or absolute)</li> </ul>"},{"location":"SPEC/#13-model-specification","title":"1.3. Model Specification","text":"<p>Kinds (depend on the format and framework)</p> <ul> <li>huggingface</li> <li>mlflow</li> <li>...</li> </ul> <p>Besides common metadata elements, the following spec elements are allowed (optional)</p> <ul> <li>framework - name of the library underlying the model</li> <li>metrics - metrics of the model specific to the type of the library</li> <li>type - fully qualified metric ID</li> <li>value - evaluated metric value</li> <li>name - human-readable metric name</li> <li>args - dictionary of parameters for the metric to be applied</li> <li>parameters - hyper parameters of the model as key-value pairs</li> <li>value - model instance as URL (relative or absolute)</li> </ul>"},{"location":"SPEC/#14-deployment-specification","title":"1.4. Deployment Specification","text":"<p>Kinds: - service - webapp - widget - monitor - ...</p> <p>Besides common metadata elements, the following spec elements are allowed (optional)</p> <ul> <li>implementation</li> <li>framework - deployment platform</li> <li>spec - implementation specification (framework-specific)</li> <li>openapi - reference to OpenAPI spec if present</li> </ul>"},{"location":"SPEC/#15-operation-specification","title":"1.5. Operation Specification","text":"<p>Kinds:</p> <ul> <li>job</li> <li>deploy</li> <li>notebook</li> <li>pipeline</li> <li>...</li> </ul> <p>Besides common metadata elements, the following spec elements are foreseen</p> <ul> <li>implementation</li> <li>framework - execution platform</li> <li>spec - implementation specification (framework-specific)</li> <li>task - the task tag the operation characterizes (optional). For example,</li> <li>For data: validate, transform</li> <li>For models: train, evaluate, monitor, optimize, adapt, serve</li> <li>For services: deploy, build</li> <li>inputs - references to the entities consumed by the operation</li> <li>outputs - references to the entities produced by the operation</li> </ul>"},{"location":"catalog/ai_list/","title":"AI Domains","text":""},{"location":"catalog/ai_list/#nlp","title":"NLP","text":"<ul> <li> <p>Document Classifier</p> <p> <code>Product Template</code></p> <p>A generic LLM-based document classifier that can be fine-tuned on arbitrary documents and taxonomies.</p> <p> Repo</p> </li> <li> <p>EuroVoc Classifier</p> <p> <code>Product</code></p> <p>Multilingual text classifier based on Bert model and fine-tuned on official EU legal documents (from EUR Lex portal)</p> <p> Repo</p> </li> <li> <p>Family Audit Classifier</p> <p> <code>Product</code></p> <p>Multiclass sequence classifier based on BERT base italian, fine-tuned on selected corpora from Municipalities's Family Audit plans.</p> <p> Repo</p> </li> <li> <p>Entity Extraction Service</p> <p> <code>Supporting Component</code></p> <p>REDIT - A relation extraction module for Tint to identify and extract the entity and relation information from  documents.</p> <p> Repo</p> </li> <li> <p>LLM for PA Dialogs</p> <p> <code>Supporting Component</code></p> <p>LLM model adapter based on LLama 3.1 that is build with \u201cfine-tuning\u201d approach and with a dataset of dialogs created  for supporting the chatbots around public services.</p> <p> Repo</p> </li> <li> <p>Dataset of dialogs for PA LLM</p> <p> <code>Supporting Component</code></p> <p>Dataset collected and curated for the creation of the LLM model using a \u201cfine-running\u201d approach necessary to support the chatbot scenario around public services.</p> <p> Repo</p> </li> <li> <p>LLM fine tuning</p> <p> <code>Product Template</code></p> <p>A generic template for fine-tuning LLM models for RAG-type scenarios using the \u201ctransformers\u201d library</p> <p> Repo</p> </li> <li> <p>RAG template</p> <p> <code>Product Template</code></p> <p>A template for a chatbot-style application using the RAG architecture, the platform\u2019s KubeAI infrastructure, and the LangChain framework for component orchestration.</p> <p> Repo </p> </li> <li> <p>First AID</p> <p> <code>Supporting Component</code></p> <p>Human-in-the-loop data collection framework for knowledge-driven generation of synthetic dialogues using LLM prompting. </p> <p> Repo </p> </li> </ul>"},{"location":"catalog/ai_list/#remote-sensing","title":"Remote Sensing","text":"<ul> <li> <p>Sentinel Tools</p> <p> <code>Supporting Component</code></p> <p>A  wrapper for the Sentinel download and preprocessing routing for the integration with the AIxPA platform.</p> <p> Repo </p> </li> <li> <p>Remote Sensing Tools</p> <p> <code>Supporting Component</code></p> <p>Image Collection Container for performing satellite image data analysis.</p> <p> Repo </p> </li> <li> <p>Flood Detection</p> <p> <code>Product Template</code></p> <p>A set of analysis tools for the flood detection using remote sensing data.</p> <p> Repo </p> </li> <li> <p>Deforestation</p> <p> <code>Product Template</code></p> <p>Python implementation for deforestation detection on satellite imagery data.</p> <p> Repo </p> </li> <li> <p>Deforestation</p> <p> <code>Product Template</code></p> <p>Pipeline for Landslides detection to detect and monitor ground deformation associated with landslides using Sentinel-1 Level-2A imagery</p> <p> Repo </p> </li> </ul>"},{"location":"catalog/ai_list/#audio","title":"Audio","text":"<ul> <li> <p>Audio Speech Recognition fine tuner</p> <p> <code>Product Template</code></p> <p>A lightweight framework for fine-tuning speech recognition designed for efficient and reproducible training. The models that follow Whisper fine-tuning, may be directly used for OpenAI-compatible service deployment.</p> <p> Repo </p> </li> <li> <p>Early Exit ASR</p> <p> <code>Product Template</code></p> <p>A project for training and exposing dynamic Conformer models for Automatic Speech Recognition (ASR) using early-exiting training techniques.</p> <p> Repo </p> </li> </ul>"},{"location":"catalog/ai_list/#video","title":"Video","text":"<ul> <li> <p>Micromind Adapter</p> <p> <code>Product Template</code></p> <p>Micromind is a tool for optimizing and adapting video analytics models for different edge platforms and performance requirements using Micromind framework.</p> <p> Repo </p> </li> </ul>"},{"location":"catalog/ai_list/#general-purpose","title":"General Purpose","text":"<ul> <li> <p>Nefertem</p> <p> <code>Library</code></p> <p>nefertem is an exetensible Python framework for monitoring and managing data quality processes.</p> <p> Repo </p> </li> <li> <p>Digital Twin Model</p> <p> <code>Library</code></p> <p>DT Model is Civic-Digital-Twins modeling framework. The framework is designed to support defining digital twins models and evaluating them in simulated environment with varying contextual conditions.</p> <p> Repo </p> </li> </ul>"},{"location":"catalog/app_list/","title":"Applications","text":""},{"location":"catalog/app_list/#document-classification","title":"Document Classification","text":"<ul> <li> <p>Document Classifier</p> <p> <code>Product Template</code></p> <p>A generic LLM-based document classifier that can be fine-tuned on arbitrary documents and taxonomies.</p> <p> Repo</p> </li> <li> <p>EuroVoc Classifier</p> <p> <code>Product</code></p> <p>Multilingual text classifier based on Bert model and fine-tuned on official EU legal documents (from EUR Lex portal)</p> <p> Repo</p> </li> <li> <p>Family Audit Classifier</p> <p> <code>Product</code></p> <p>Multiclass sequence classifier based on BERT base italian, fine-tuned on selected corpora from Municipalities's Family Audit plans.</p> <p> Repo</p> </li> </ul>"},{"location":"catalog/app_list/#chatbot-and-advanced-dialogs","title":"Chatbot and advanced dialogs","text":"<ul> <li> <p>LLM for PA Dialogs</p> <p> <code>Supporting Component</code></p> <p>LLM model adapter based on LLama 3.1 that is build with \u201cfine-tuning\u201d approach and with a dataset of dialogs created  for supporting the chatbots around public services.</p> <p> Repo</p> </li> <li> <p>Dataset of dialogs for PA LLM</p> <p> <code>Supporting Component</code></p> <p>Dataset collected and curated for the creation of the LLM model using a \u201cfine-running\u201d approach necessary to support the chatbot scenario around public services.</p> <p> Repo</p> </li> <li> <p>LLM fine tuning</p> <p> <code>Product Template</code></p> <p>A generic template for fine-tuning LLM models for RAG-type scenarios using the \u201ctransformers\u201d library</p> <p> Repo</p> </li> <li> <p>RAG template</p> <p> <code>Product Template</code></p> <p>A template for a chatbot-style application using the RAG architecture, the platform\u2019s KubeAI infrastructure, and the LangChain framework for component orchestration.</p> <p> Repo </p> </li> <li> <p>First AID</p> <p> <code>Supporting Component</code></p> <p>Human-in-the-loop data collection framework for knowledge-driven generation of synthetic dialogues using LLM prompting. </p> <p> Repo </p> </li> </ul>"},{"location":"catalog/app_list/#information-extraction","title":"Information Extraction","text":"<ul> <li> <p>Entity Extraction Service</p> <p> <code>Supporting Component</code></p> <p>REDIT - A relation extraction module for Tint to identify and extract the entity and relation information from  documents.</p> <p> Repo</p> </li> </ul>"},{"location":"catalog/app_list/#enivronmental-protection","title":"Enivronmental Protection","text":"<ul> <li> <p>Sentinel Tools</p> <p> <code>Supporting Component</code></p> <p>A  wrapper for the Sentinel download and preprocessing routing for the integration with the AIxPA platform.</p> <p> Repo</p> </li> <li> <p>Remote Sensing Tools</p> <p> <code>Supporting Component</code></p> <p>Image Collection Container for performing satellite image data analysis.</p> <p> Repo</p> </li> <li> <p>Flood Detection</p> <p> <code>Product Template</code></p> <p>A set of analysis tools for the flood detection using remote sensing data.</p> <p> Repo</p> </li> <li> <p>Deforestation</p> <p> <code>Product Template</code></p> <p>Python implementation for deforestation detection on satellite imagery data.</p> <p> Repo</p> </li> <li> <p>Deforestation</p> <p> <code>Product Template</code></p> <p>Pipeline for Landslides detection to detect and monitor ground deformation associated with landslides using Sentinel-1 Level-2A imagery</p> <p> Repo</p> </li> </ul>"},{"location":"catalog/app_list/#automated-speech-recognition","title":"Automated Speech Recognition","text":"<ul> <li> <p>Audio Speech Recognition fine tuner</p> <p> <code>Product Template</code></p> <p>A lightweight framework for fine-tuning speech recognition designed for efficient and reproducible training. The models that follow Whisper fine-tuning, may be directly used for OpenAI-compatible service deployment.</p> <p> Repo </p> </li> <li> <p>Early Exit ASR</p> <p> <code>Product Template</code></p> <p>A project for training and exposing dynamic Conformer models for Automatic Speech Recognition (ASR) using early-exiting training techniques.</p> <p> Repo </p> </li> </ul>"},{"location":"catalog/app_list/#decision-making","title":"Decision Making","text":"<ul> <li> <p>Digital Twin Model</p> <p> <code>Library</code></p> <p>DT Model is Civic-Digital-Twins modeling framework. The framework is designed to support defining digital twins models and evaluating them in simulated environment with varying contextual conditions.</p> <p> Repo </p> </li> </ul>"},{"location":"catalog/app_list/#data-quality","title":"Data Quality","text":"<ul> <li> <p>Nefertem</p> <p> <code>Library</code></p> <p>nefertem is an exetensible Python framework for monitoring and managing data quality processes.</p> <p> Repo </p> </li> </ul>"},{"location":"catalog/kind_list/","title":"Types of Tools","text":""},{"location":"catalog/kind_list/#product-templates","title":"Product Templates","text":"<ul> <li> <p>Document Classifier</p> <p> <code>Product Template</code></p> <p>A generic LLM-based document classifier that can be fine-tuned on arbitrary documents and taxonomies.</p> <p> Repo</p> </li> <li> <p>LLM fine tuning</p> <p> <code>Product Template</code></p> <p>A generic template for fine-tuning LLM models for RAG-type scenarios using the \u201ctransformers\u201d library</p> <p> Repo</p> </li> <li> <p>RAG template</p> <p> <code>Product Template</code></p> <p>A template for a chatbot-style application using the RAG architecture, the platform\u2019s KubeAI infrastructure, and the LangChain framework for component orchestration.</p> <p> Repo</p> </li> <li> <p>Flood Detection</p> <p> <code>Product Template</code></p> <p>A set of analysis tools for the flood detection using remote sensing data.</p> <p> Repo</p> </li> <li> <p>Deforestation</p> <p> <code>Product Template</code></p> <p>Python implementation for deforestation detection on satellite imagery data.</p> <p> Repo</p> </li> <li> <p>Deforestation</p> <p> <code>Product Template</code></p> <p>Pipeline for Landslides detection to detect and monitor ground deformation associated with landslides using Sentinel-1 Level-2A imagery</p> <p> Repo</p> </li> <li> <p>Early Exit ASR</p> <p> <code>Product Template</code></p> <p>A project for training and exposing dynamic Conformer models for Automatic Speech Recognition (ASR) using early-exiting training techniques.</p> <p> Repo</p> </li> <li> <p>Audio Speech Recognition fine tuner</p> <p> <code>Product Template</code></p> <p>A lightweight framework for fine-tuning speech recognition designed for efficient and reproducible training. The models that follow Whisper fine-tuning, may be directly used for OpenAI-compatible service deployment.</p> <p> Repo</p> </li> <li> <p>Micromind Adapter</p> <p> <code>Product Template</code></p> <p>Micromind is a tool for optimizing and adapting video analytics models for different edge platforms and performance requirements using Micromind framework.</p> <p> Repo</p> </li> </ul>"},{"location":"catalog/kind_list/#products","title":"Products","text":"<ul> <li> <p>EuroVoc Classifier</p> <p> <code>Product</code></p> <p>Multilingual text classifier based on Bert model and fine-tuned on official EU legal documents (from EUR Lex portal)</p> <p> Repo</p> </li> <li> <p>Family Audit Classifier</p> <p> <code>Product</code></p> <p>Multiclass sequence classifier based on BERT base italian, fine-tuned on selected corpora from Municipalities's Family Audit plans.</p> <p> Repo</p> </li> </ul>"},{"location":"catalog/kind_list/#supporting-components","title":"Supporting Components","text":"<ul> <li> <p>Entity Extraction Service</p> <p> <code>Supporting Component</code></p> <p>REDIT - A relation extraction module for Tint to identify and extract the entity and relation information from  documents.</p> <p> Repo</p> </li> <li> <p>LLM for PA Dialogs</p> <p> <code>Supporting Component</code></p> <p>LLM model adapter based on LLama 3.1 that is build with \u201cfine-tuning\u201d approach and with a dataset of dialogs created  for supporting the chatbots around public services.</p> <p> Repo</p> </li> <li> <p>Dataset of dialogs for PA LLM</p> <p> <code>Supporting Component</code></p> <p>Dataset collected and curated for the creation of the LLM model using a \u201cfine-running\u201d approach necessary to support the chatbot scenario around public services.</p> <p> Repo</p> </li> <li> <p>Sentinel Tools</p> <p> <code>Supporting Component</code></p> <p>A  wrapper for the Sentinel download and preprocessing routing for the integration with the AIxPA platform.</p> <p> Repo</p> </li> <li> <p>Remote Sensing Tools</p> <p> <code>Supporting Component</code></p> <p>Image Collection Container for performing satellite image data analysis.</p> <p> Repo</p> </li> <li> <p>First AID</p> <p> <code>Supporting Component</code></p> <p>Human-in-the-loop data collection framework for knowledge-driven generation of synthetic dialogues using LLM prompting. </p> <p> Repo</p> </li> </ul>"},{"location":"catalog/kind_list/#libraries","title":"Libraries","text":"<ul> <li> <p>Nefertem</p> <p> <code>Library</code></p> <p>nefertem is an exetensible Python framework for monitoring and managing data quality processes.</p> <p> Repo</p> </li> <li> <p>Digital Twin Model</p> <p> <code>Library</code></p> <p>DT Model is Civic-Digital-Twins modeling framework. The framework is designed to support defining digital twins models and evaluating them in simulated environment with varying contextual conditions.</p> <p> Repo</p> </li> </ul>"},{"location":"catalog/tools/aixpa-first-aid/","title":"Aixpa first aid","text":"<p>First AID</p> <pre><code>---\n\n:material-tag: ``Supporting Component``\n\n\nHuman-in-the-loop data collection framework for knowledge-driven generation of synthetic dialogues using LLM prompting.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/api-first-AID-AIXPA ){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/asr-fine-tuning/","title":"Asr fine tuning","text":"<p>Audio Speech Recognition fine tuner</p> <pre><code>---\n\n:material-tag: ``Product Template``\n\nA lightweight framework for fine-tuning speech recognition designed for efficient and reproducible training. The models that follow Whisper fine-tuning, may be directly used for OpenAI-compatible service deployment.\n\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/asr-fine-tuning ){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/document-classifier/","title":"Document classifier","text":"<p>Document Classifier</p> <pre><code>---\n\n:material-tag: ``Product Template``\n\nA generic LLM-based document classifier that can be fine-tuned on arbitrary documents and taxonomies.\n\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/document-classifier){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/dt-model/","title":"Dt model","text":"<p>Digital Twin Model</p> <pre><code>---\n\n:material-tag: ``Library``\n\nDT Model is Civic-Digital-Twins modeling framework. The framework is designed to support defining digital twins models and evaluating them in simulated environment with varying contextual conditions.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/dt-model){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/early-exit/","title":"Early exit","text":"<p>Early Exit ASR</p> <pre><code>---\n\n:material-tag: ``Product Template``\n\nA project for training and exposing dynamic Conformer models for Automatic Speech Recognition (ASR) using early-exiting training techniques.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/audio-early-exit-transformer){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/eurovoc-classifier/","title":"Eurovoc classifier","text":"<p>EuroVoc Classifier</p> <pre><code>---\n\n:material-tag: ``Product``\n\nMultilingual text classifier based on Bert model and fine-tuned on official EU legal documents (from EUR Lex portal)\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/eurovoc-classifier){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/faudit-classifier/","title":"Faudit classifier","text":"<p>Family Audit Classifier</p> <pre><code>---\n\n:material-tag: ``Product``\n\nMulticlass sequence classifier based on BERT base italian, fine-tuned on selected corpora from Municipalities's Family Audit plans.\n\n[:octicons-arrow-right-24: Repo](https://github.com/FluveFV/faudit-classifier){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/llm-fine-tuner/","title":"Llm fine tuner","text":"<p>LLM fine tuning</p> <pre><code>---\n\n:material-tag: ``Product Template``\n\nA generic template for fine-tuning LLM models for RAG-type scenarios using the \u201ctransformers\u201d library\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/llm-fine-tuner ){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/llm-pa-dialog-dataset/","title":"Llm pa dialog dataset","text":"<p>Dataset of dialogs for PA LLM</p> <pre><code>---\n\n:material-tag: ``Supporting Component``\n\nDataset collected and curated for the creation of the LLM model using a \u201cfine-running\u201d approach necessary to support the chatbot scenario around public services.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/llm-pa-dialog-dataset){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/llm-pa/","title":"Llm pa","text":"<p>LLM for PA Dialogs</p> <pre><code>---\n\n:material-tag: ``Supporting Component``\n\nLLM model adapter based on LLama 3.1 that is build with \u201cfine-tuning\u201d approach and with a dataset of dialogs created \nfor supporting the chatbots around public services.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/llm-pa){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/micromind/","title":"Micromind","text":"<p>Micromind Adapter</p> <pre><code>---\n\n:material-tag: ``Product Template``\n\nMicromind is a tool for optimizing and adapting video analytics models for different edge platforms and performance requirements\nusing Micromind framework.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/micromind-adapter){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/nefertem/","title":"Nefertem","text":"<p>Nefertem</p> <pre><code>---\n\n:material-tag: ``Library``\n\nnefertem is an exetensible Python framework for monitoring and managing data quality processes.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/nefertem){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/rag-template/","title":"Rag template","text":"<p>RAG template</p> <pre><code>---\n\n:material-tag: ``Product Template``\n\nA template for a chatbot-style application using the RAG architecture, the platform\u2019s KubeAI infrastructure, and the LangChain framework for component orchestration.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/rag-template){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/redit/","title":"Redit","text":"<p>Entity Extraction Service</p> <pre><code>---\n\n:material-tag: ``Supporting Component``\n\nREDIT - A relation extraction module for Tint to identify and extract the entity and relation information from  documents.\n\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/redit){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/rs-deforestation/","title":"Rs deforestation","text":"<p>Deforestation</p> <pre><code>---\n\n:material-tag: ``Product Template``\n\nPython implementation for deforestation detection on satellite imagery data.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/rs-deforestation){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/rs-flood/","title":"Rs flood","text":"<p>Flood Detection</p> <pre><code>---\n\n:material-tag: ``Product Template``\n\nA set of analysis tools for the flood detection using remote sensing data.\n\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/rs-flood-mapping){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/rs-landsline/","title":"Rs landsline","text":"<p>Deforestation</p> <pre><code>---\n\n:material-tag: ``Product Template``\n\nPipeline for Landslides detection to detect and monitor ground deformation associated with landslides using Sentinel-1 Level-2A imagery\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/rs-landslide-monitoring){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/rs-tools/","title":"Rs tools","text":"<p>Remote Sensing Tools</p> <pre><code>---\n\n:material-tag: ``Supporting Component``\n\nImage Collection Container for performing satellite image data analysis.\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/sentinel-tools){:target=\"_blank\"}\n</code></pre>"},{"location":"catalog/tools/sentinel-tools/","title":"Sentinel tools","text":"<p>Sentinel Tools</p> <pre><code>---\n\n:material-tag: ``Supporting Component``\n\nA  wrapper for the Sentinel download and preprocessing routing for the integration with the AIxPA platform.\n\n\n[:octicons-arrow-right-24: Repo](https://github.com/tn-aixpa/sentinel-tools){:target=\"_blank\"}\n</code></pre>"}]}